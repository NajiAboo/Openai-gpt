{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Video Summarization Steps\n",
        "### Convert frames to base64\n",
        "### Get audio content\n",
        "### Summarize the video only\n",
        "### summarize the audio only\n",
        "### summarize both audio and video together"
      ],
      "metadata": {
        "id": "Csv5zZKUeTA2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade openai --quiet\n",
        "%pip install opencv-python --quiet\n",
        "%pip install moviepy --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1-H_LF8eQrq",
        "outputId": "369429f5-bec2-4dc7-ed68-9b4d2f3a97ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/320.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/320.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "open_ai_api_key = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "O-ieAJnXe4mu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "model = \"gpt-4o\"\n",
        "client = OpenAI(api_key= open_ai_api_key)"
      ],
      "metadata": {
        "id": "-Q1g003te4pB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from moviepy.editor import VideoFileClip\n",
        "import time\n",
        "import base64"
      ],
      "metadata": {
        "id": "620SoAife4rX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VIDEO_PATH = \"/content/keynote_recap.mp4\""
      ],
      "metadata": {
        "id": "vV8Icinxhunv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_video(video_path, seconds_per_frame =2 ):\n",
        "  base64frames = []\n",
        "  base_video_path,_ = os.path.splitext(video_path)\n",
        "  print(base_video_path)\n",
        "\n",
        "  video = cv2.VideoCapture(video_path)\n",
        "  total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "  fps = video.get(cv2.CAP_PROP_FPS)\n",
        "  frames_to_skip = int(fps*seconds_per_frame)\n",
        "\n",
        "  curr_frame = 0\n",
        "\n",
        "  while curr_frame < total_frames - 1:\n",
        "    video.set(cv2.CAP_PROP_POS_FRAMES, curr_frame)\n",
        "    sucess, frame = video.read()\n",
        "\n",
        "    if not sucess:\n",
        "      break\n",
        "\n",
        "    _, buffer = cv2.imencode(\".jpg\", frame)\n",
        "    base64frames.append(base64.b64encode(buffer).decode(\"utf-8\"))\n",
        "    curr_frame = curr_frame + frames_to_skip\n",
        "\n",
        "  video.release()\n",
        "\n",
        "  audio_path = f\"{base_video_path}.mp3\"\n",
        "  clip = VideoFileClip(video_path)\n",
        "  clip.audio.write_audiofile(audio_path, bitrate=\"32k\")\n",
        "  clip.audio.close()\n",
        "  clip.close()\n",
        "\n",
        "  return base64frames, audio_path\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PYB2GFDnhup9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base64_frames, audio_path = process_video(VIDEO_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnI11aWJhusV",
        "outputId": "3ad810bd-460d-4b3e-c1cd-e0a5122cb718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/keynote_recap\n",
            "MoviePy - Writing audio in /content/keynote_recap.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base64_frames = base64_frames[::20]"
      ],
      "metadata": {
        "id": "D4PQ5XNre4tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "respose = client.chat.completions.create(\n",
        "    model = model,\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are generating a video summary, Please provide a summary of the video, repond in Markdown\"\n",
        "        },\n",
        "        {\n",
        "            \"role\" : \"user\",\n",
        "            \"content\": [\n",
        "                \"There are the frames from the video\",\n",
        "                *map(lambda x: {\"type\": \"image_url\",\n",
        "                                \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}\n",
        "\n",
        "                }, base64_frames)\n",
        "            ]\n",
        "        }\n",
        "    ],\n",
        "    temperature = 0,\n",
        ")"
      ],
      "metadata": {
        "id": "Z7g-7zJTe4wE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(respose.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09EkBlhRe4y6",
        "outputId": "5a214f2a-7f5c-4c1d-cb7b-2327e664b188"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Video Summary\n",
            "\n",
            "The video appears to be a presentation from an event called \"OpenAI DevDay.\" The presentation includes the following key points:\n",
            "\n",
            "1. **Introduction Slide**: The video starts with a title slide displaying \"OpenAI DevDay.\"\n",
            "2. **Function Calling Slide**: A slide explaining the concept of function calling, showing a \"before\" and \"after\" scenario of how commands are processed.\n",
            "3. **Presenter**: A person is seen speaking on stage, likely the main presenter of the event.\n",
            "4. **Key Topics Slide**: The presentation covers three main topics: Instructions, Expanded Knowledge, and Actions.\n",
            "5. **Presenter's Speech**: The presenter continues to elaborate on the topics, engaging with the audience.\n",
            "6. **Closing Gesture**: The presenter waves, possibly indicating the end of the presentation or a segment.\n",
            "\n",
            "The video seems to focus on advancements in AI, particularly in how functions are called and executed, and the broader implications of these advancements.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rU8BhsJHl9Pf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}